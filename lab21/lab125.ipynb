{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "from playwright.async_api import async_playwright\n",
    "from unstructured.partition.html import partition_html\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"SERPER_API_KEY\"] = \"\" # serper.dev API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "\n",
    "\n",
    "from crewai import Agent\n",
    "from crewai import Task\n",
    "from textwrap import dedent\n",
    "from datetime import date\n",
    "\n",
    "from crewai_tools import SerperDevTool\n",
    "search_tool = SerperDevTool()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def scrape_and_summarize_website(website):\n",
    "  try: \n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch()\n",
    "        page = await browser.new_page()\n",
    "        await page.goto(website)\n",
    "        content = await page.content()\n",
    "        await browser.close()\n",
    "\n",
    "    elements = partition_html(text=content)\n",
    "    content = \"\\n\\n\".join([str(el) for el in elements])\n",
    "    content = [content[i:i + 8000] for i in range(0, len(content), 8000)]\n",
    "    summaries = []\n",
    "    for chunk in content:\n",
    "        agent = Agent(\n",
    "            role='Principal Researcher',\n",
    "            goal='Do amazing research and summaries based on the content you are working with',\n",
    "            backstory=\"You're a Principal Researcher at a big company and you need to do research about a given topic.\",\n",
    "            allow_delegation=False\n",
    "        )\n",
    "        task = Task(\n",
    "            description='Find and summarize the latest and most relevant news on AI',\n",
    "            agent=agent\n",
    "        )\n",
    "        summary = task.execute()\n",
    "        summaries.append(summary)\n",
    "    return \"\\n\\n\".join(summaries)\n",
    "  except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import html\n",
    "from html.parser import HTMLParser\n",
    "\n",
    "class HTMLTextExtractor(HTMLParser):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.text = []\n",
    "\n",
    "    def handle_data(self, data):\n",
    "        self.text.append(data)\n",
    "\n",
    "    def get_text(self):\n",
    "        return ''.join(self.text)\n",
    "\n",
    "def extract_text_from_html(html_content):\n",
    "    parser = HTMLTextExtractor()\n",
    "    parser.feed(html_content)\n",
    "    return parser.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: 1 validation error for Task\n",
      "expected_output\n",
      "  Field required [type=missing, input_value={'description': 'Find and...h about a given topic.)}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.6/v/missing\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"NoneType\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m website \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://livebook.myidea.my.id/authenticate\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m idata\u001b[38;5;241m=\u001b[39mnew_loop\u001b[38;5;241m.\u001b[39mrun_until_complete(scrape_and_summarize_website(website))\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mextract_text_from_html\u001b[49m\u001b[43m(\u001b[49m\u001b[43midata\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      9\u001b[0m new_loop\u001b[38;5;241m.\u001b[39mclose()\n",
      "Cell \u001b[0;32mIn[4], line 17\u001b[0m, in \u001b[0;36mextract_text_from_html\u001b[0;34m(html_content)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_text_from_html\u001b[39m(html_content):\n\u001b[1;32m     16\u001b[0m     parser \u001b[38;5;241m=\u001b[39m HTMLTextExtractor()\n\u001b[0;32m---> 17\u001b[0m     \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhtml_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mget_text()\n",
      "File \u001b[0;32m~/.conda/envs/crewai/lib/python3.11/html/parser.py:109\u001b[0m, in \u001b[0;36mHTMLParser.feed\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Feed data to the parser.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    Call this as often as you want, with as little or as much text\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;124;03m    as you want (may include '\\n').\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrawdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrawdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgoahead(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"NoneType\") to str"
     ]
    }
   ],
   "source": [
    "new_loop = asyncio.new_event_loop()\n",
    "asyncio.set_event_loop(new_loop)\n",
    "\n",
    "website = \"https://livebook.myidea.my.id/authenticate\"\n",
    "idata=new_loop.run_until_complete(scrape_and_summarize_website(website))\n",
    "\n",
    "print(extract_text_from_html(idata))\n",
    "\n",
    "new_loop.close()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
