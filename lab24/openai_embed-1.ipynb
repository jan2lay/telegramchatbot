{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Union\n",
    "from embeddings_util import EmbeddingsUtil\n",
    "\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "\n",
    "embedding_encoding = \"cl100k_base\"\n",
    "max_tokens = 8000\n",
    "\n",
    "embedding_client = EmbeddingsUtil(\n",
    "    api_key = \"\",\n",
    "    verbose = True,  \n",
    "    embedding_model = \"text-embedding-3-small\",\n",
    "    chunk_max_tokens = 8000, \n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load & inspect dataset\n",
    "input_datapath = \"data_test1.csv\"  # to save space, we provide a pre-filtered dataset\n",
    "df = pd.read_csv(input_datapath, index_col=0)\n",
    "df = df[[\"Time\", \"ProductId\", \"UserId\", \"Score\", \"Summary\", \"Text\"]]\n",
    "df = df.dropna()\n",
    "df[\"combined\"] = (\n",
    "    \"Title: \" + df.Summary.str.strip() + \"; Content: \" + df.Text.str.strip()\n",
    ")\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsample to 1k most recent reviews and remove samples that are too long\n",
    "\n",
    "top_n = 1000\n",
    "df = df.sort_values(\"Time\").tail(top_n * 2)  # first cut to first 2k entries, assuming less than half will be filtered out\n",
    "df.drop(\"Time\", axis=1, inplace=True)\n",
    "\n",
    "encoding = tiktoken.get_encoding(embedding_encoding)\n",
    "\n",
    "# omit reviews that are too long to embed\n",
    "df[\"n_tokens\"] = df.combined.apply(lambda x: len(encoding.encode(x)))\n",
    "df = df[df.n_tokens <= max_tokens].tail(top_n)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data_test1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embedding_for_text(self,text: str) -> List[float]:\n",
    "    \"\"\"\n",
    "    Generates an embedding for a given text using the OpenAI API.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text to generate an embedding for.\n",
    "\n",
    "    Returns:\n",
    "        List[float]: The generated embedding as a list of floats.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        embedding = self.openai_call(text, \"/v1/embeddings\", self.embedding_model)\n",
    "        return embedding\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating embedding: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text_to_embed = \"This is an example text for embedding.\"\n",
    "\n",
    "embedding_result = generate_embedding_for_text(text_to_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to generate embedding.\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "class EmbeddingGenerator:\n",
    "    def __init__(self, embedding_model: str, api_key: str):\n",
    "        self.embedding_model = embedding_model\n",
    "        self.api_key = api_key\n",
    "        # Initialize any other necessary properties or dependencies\n",
    "\n",
    "    def openai_call(self, text: str, endpoint: str, model: str) -> List[float]:\n",
    "        # Implementation for making the OpenAI API call goes here\n",
    "        # This function should return the embedding as a list of floats\n",
    "        pass\n",
    "\n",
    "    def generate_embedding_for_text(self, text: str) -> List[float]:\n",
    "        try:\n",
    "            embedding = self.openai_call(text, \"/v1/embeddings\", self.embedding_model)\n",
    "            return embedding\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating embedding: {e}\")\n",
    "            return []\n",
    "\n",
    "# Create an instance of the EmbeddingGenerator class\n",
    "embedding_generator = EmbeddingGenerator(embedding_model=\"text-embedding-3-small\", api_key=\"\")\n",
    "\n",
    "# Call the generate_embedding_for_text method\n",
    "text = \"This is an example text for generating embeddings.\"\n",
    "embedding = embedding_generator.generate_embedding_for_text(text)\n",
    "\n",
    "if embedding:\n",
    "    print(f\"Embedding for '{text}': {embedding}\")\n",
    "else:\n",
    "    print(\"Failed to generate embedding.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
